{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7kxwViglXkv"
   },
   "source": [
    "# CV and Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OeYGSjUKll8U"
   },
   "source": [
    "Q1. Import tensorflow (2.x Mandatory)\n",
    "\n",
    "*   Import other required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "or2c_abbl8rk",
    "outputId": "86bb2a3e-b30f-4a38-a5ce-1b8f2226c5b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "% tensorflow_version 2.x\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGrQe1WUl1SZ"
   },
   "source": [
    "Q2. Load CIFAR10 dataset from keras and split into train and test\n",
    "*    Identify shape of x_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZIA_FBhPminY",
    "outputId": "409f84a1-bc57-4cd9-cffc-6e6f93ac3dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Load CIFAR10 dataset available within tensorflow\n",
    "(train_x, train_y),(test_x,test_y) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "bUCJEFjfD-BF",
    "outputId": "94f261af-c431-4c94-9721-a5f9c3a5c828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_x : (50000, 32, 32, 3)\n",
      "Shape of test_x : (10000, 32, 32, 3)\n",
      "Shape of train_y : (50000, 1)\n",
      "Shape of test_y : (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Shape of train_x :', train_x.shape)\n",
    "print ('Shape of test_x :', test_x.shape)\n",
    "print ('Shape of train_y :', train_y.shape)\n",
    "print ('Shape of test_y :', test_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wrk2ohBxmmTx"
   },
   "source": [
    "Q3.\n",
    "\n",
    "*   Transform x_train and x_test on scale of 0-1\n",
    "*   Transform y_train and y_test to categories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gFXxAJe41Pe"
   },
   "outputs": [],
   "source": [
    "# to normalize train_x and test_x\n",
    "x_train = train_x/255\n",
    "x_test = test_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8yirvKf-GHJH"
   },
   "outputs": [],
   "source": [
    "#Convert labels to one hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(train_y, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(test_y, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "f3BcvIsUGWfM",
    "outputId": "ca094f4f-050c-4dc4-e951-4c9191fa4884"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEVCAYAAAAmS5PgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd3bHSQj/D0666HCtRDvyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's review the data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img_num = np.random.randint(0, test_x.shape[0]) #Get a random integer between 0 and number of examples in test dataset\n",
    "plt.imshow(test_x[img_num],cmap='gray') #Show the image from test dataset\n",
    "plt.suptitle('Number: ' + str(y_test[img_num]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MP5j5MhDzuYc"
   },
   "source": [
    "Q4. Import necessary packages required for Model building\n",
    "*   Conv2D, Dense, Flatten, Dropout, MaxPooling2D etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lSgCiFid5eb7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout,Activation\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjR-5jryHqKG"
   },
   "outputs": [],
   "source": [
    "#Clear out tensorflow memory\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQBgmSJdz1fq"
   },
   "source": [
    "Q5. Prepare a CNN\n",
    " \n",
    "*   Which will include above layers\n",
    "*   Freely create your own Architecture and Arguments\n",
    "*   Print Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1IXruOry648i"
   },
   "outputs": [],
   "source": [
    "# Sequential\n",
    "model = Sequential()\n",
    "\n",
    "# 1st CNN layer\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 2nd CNN layer \n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Max pool layer \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25)) # dropout = 25%\n",
    "\n",
    "# third CNN layer \n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 4th CNN layer \n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# max pool  2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25)) # Dropout = 25%\n",
    "\n",
    "# Flattening the layer \n",
    "model.add(Flatten())\n",
    "\n",
    "# Dens layer \n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5)) # drpout\n",
    "\n",
    "# Output layer \n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJWewXLdIdr9"
   },
   "outputs": [],
   "source": [
    "#Specify Loass and Optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "FR3A2j2kI6j8",
    "outputId": "087f6189-6324-46c6-8a62-7b48ba991b06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gyZhZciC0qvw"
   },
   "source": [
    "Q6. Train the CNN\n",
    "\n",
    "*   Compile the model\n",
    "*   Fit the model (10 epochs, 32 batch size)\n",
    "*   Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bONoYIbnMn5T"
   },
   "outputs": [],
   "source": [
    "mckpt = tf.keras.callbacks.ModelCheckpoint('./cifar.h5', \n",
    "                                           monitor='val_acc', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "ApU5xo7h6rxL",
    "outputId": "1c451de7-55d1-4a34-c9bb-b72c37520ad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "49632/50000 [============================>.] - ETA: 0s - loss: 1.5442 - accuracy: 0.4349WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 15s 296us/sample - loss: 1.5420 - accuracy: 0.4360 - val_loss: 1.1585 - val_accuracy: 0.5875\n",
      "Epoch 2/5\n",
      "49888/50000 [============================>.] - ETA: 0s - loss: 1.1342 - accuracy: 0.5983WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 1.1338 - accuracy: 0.5985 - val_loss: 0.9729 - val_accuracy: 0.6568\n",
      "Epoch 3/5\n",
      "49696/50000 [============================>.] - ETA: 0s - loss: 0.9930 - accuracy: 0.6508WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 167us/sample - loss: 0.9923 - accuracy: 0.6510 - val_loss: 0.8816 - val_accuracy: 0.6939\n",
      "Epoch 4/5\n",
      "49760/50000 [============================>.] - ETA: 0s - loss: 0.8974 - accuracy: 0.6852WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.8975 - accuracy: 0.6852 - val_loss: 0.8054 - val_accuracy: 0.7209\n",
      "Epoch 5/5\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.8295 - accuracy: 0.7084WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 166us/sample - loss: 0.8298 - accuracy: 0.7083 - val_loss: 0.7749 - val_accuracy: 0.7286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f655002a2e8>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,          \n",
    "          validation_data=(x_test,y_test),\n",
    "          epochs=5,\n",
    "          batch_size=32, callbacks=[mckpt],workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1eOQz7brOGzO",
    "outputId": "5e139ce8-cef1-439b-abec-d68f8fca7ba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "49760/50000 [============================>.] - ETA: 0s - loss: 0.7789 - accuracy: 0.7263WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.7793 - accuracy: 0.7261 - val_loss: 0.7351 - val_accuracy: 0.7487\n",
      "Epoch 2/50\n",
      "49888/50000 [============================>.] - ETA: 0s - loss: 0.7403 - accuracy: 0.7403WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.7402 - accuracy: 0.7404 - val_loss: 0.7195 - val_accuracy: 0.7547\n",
      "Epoch 3/50\n",
      "49728/50000 [============================>.] - ETA: 0s - loss: 0.7108 - accuracy: 0.7522WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.7108 - accuracy: 0.7523 - val_loss: 0.6849 - val_accuracy: 0.7701\n",
      "Epoch 4/50\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.6841 - accuracy: 0.7609WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.6839 - accuracy: 0.7609 - val_loss: 0.6593 - val_accuracy: 0.7741\n",
      "Epoch 5/50\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.6585 - accuracy: 0.7680WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.6587 - accuracy: 0.7680 - val_loss: 0.6685 - val_accuracy: 0.7790\n",
      "Epoch 6/50\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.6377 - accuracy: 0.7759WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.6374 - accuracy: 0.7759 - val_loss: 0.6647 - val_accuracy: 0.7744\n",
      "Epoch 7/50\n",
      "49728/50000 [============================>.] - ETA: 0s - loss: 0.6211 - accuracy: 0.7834WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.6218 - accuracy: 0.7832 - val_loss: 0.6513 - val_accuracy: 0.7739\n",
      "Epoch 8/50\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.5995 - accuracy: 0.7890WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.5998 - accuracy: 0.7889 - val_loss: 0.6658 - val_accuracy: 0.7716\n",
      "Epoch 9/50\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.5876 - accuracy: 0.7935WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.5880 - accuracy: 0.7935 - val_loss: 0.6693 - val_accuracy: 0.7724\n",
      "Epoch 10/50\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.5719 - accuracy: 0.7991WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.5715 - accuracy: 0.7991 - val_loss: 0.6646 - val_accuracy: 0.7744\n",
      "Epoch 11/50\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.5630 - accuracy: 0.8016WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.5629 - accuracy: 0.8017 - val_loss: 0.6543 - val_accuracy: 0.7771\n",
      "Epoch 12/50\n",
      "49760/50000 [============================>.] - ETA: 0s - loss: 0.5501 - accuracy: 0.8070WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.5504 - accuracy: 0.8069 - val_loss: 0.6482 - val_accuracy: 0.7863\n",
      "Epoch 13/50\n",
      "49888/50000 [============================>.] - ETA: 0s - loss: 0.5445 - accuracy: 0.8094WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.5448 - accuracy: 0.8093 - val_loss: 0.6213 - val_accuracy: 0.7901\n",
      "Epoch 14/50\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.5263 - accuracy: 0.8135WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.5261 - accuracy: 0.8135 - val_loss: 0.6466 - val_accuracy: 0.7880\n",
      "Epoch 15/50\n",
      "49760/50000 [============================>.] - ETA: 0s - loss: 0.5179 - accuracy: 0.8174WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.5182 - accuracy: 0.8172 - val_loss: 0.6281 - val_accuracy: 0.7923\n",
      "Epoch 16/50\n",
      "49760/50000 [============================>.] - ETA: 0s - loss: 0.5097 - accuracy: 0.8189WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.5101 - accuracy: 0.8187 - val_loss: 0.6609 - val_accuracy: 0.7830\n",
      "Epoch 17/50\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.5004 - accuracy: 0.8250WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.5004 - accuracy: 0.8251 - val_loss: 0.6386 - val_accuracy: 0.7863\n",
      "Epoch 18/50\n",
      "49696/50000 [============================>.] - ETA: 0s - loss: 0.5014 - accuracy: 0.8229WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.5008 - accuracy: 0.8230 - val_loss: 0.6562 - val_accuracy: 0.7859\n",
      "Epoch 19/50\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.4921 - accuracy: 0.8266WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 168us/sample - loss: 0.4923 - accuracy: 0.8266 - val_loss: 0.6300 - val_accuracy: 0.7880\n",
      "Epoch 20/50\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.4889 - accuracy: 0.8269WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 168us/sample - loss: 0.4890 - accuracy: 0.8269 - val_loss: 0.6405 - val_accuracy: 0.7858\n",
      "Epoch 21/50\n",
      "49664/50000 [============================>.] - ETA: 0s - loss: 0.4758 - accuracy: 0.8340WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.4758 - accuracy: 0.8341 - val_loss: 0.6362 - val_accuracy: 0.7919\n",
      "Epoch 22/50\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.4666 - accuracy: 0.8370WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.4667 - accuracy: 0.8370 - val_loss: 0.6712 - val_accuracy: 0.7846\n",
      "Epoch 23/50\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.4645 - accuracy: 0.8367WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.4649 - accuracy: 0.8367 - val_loss: 0.6366 - val_accuracy: 0.7915\n",
      "Epoch 24/50\n",
      "49696/50000 [============================>.] - ETA: 0s - loss: 0.4608 - accuracy: 0.8392WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.4605 - accuracy: 0.8393 - val_loss: 0.6242 - val_accuracy: 0.7951\n",
      "Epoch 25/50\n",
      "49664/50000 [============================>.] - ETA: 0s - loss: 0.4516 - accuracy: 0.8437WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.4515 - accuracy: 0.8436 - val_loss: 0.6454 - val_accuracy: 0.7933\n",
      "Epoch 26/50\n",
      "49760/50000 [============================>.] - ETA: 0s - loss: 0.4524 - accuracy: 0.8411WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 166us/sample - loss: 0.4527 - accuracy: 0.8408 - val_loss: 0.6614 - val_accuracy: 0.7835\n",
      "Epoch 27/50\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.4478 - accuracy: 0.8434WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.4479 - accuracy: 0.8434 - val_loss: 0.6541 - val_accuracy: 0.7892\n",
      "Epoch 28/50\n",
      "49728/50000 [============================>.] - ETA: 0s - loss: 0.4436 - accuracy: 0.8443WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.4436 - accuracy: 0.8443 - val_loss: 0.6487 - val_accuracy: 0.7940\n",
      "Epoch 29/50\n",
      "49632/50000 [============================>.] - ETA: 0s - loss: 0.4318 - accuracy: 0.8514WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.4319 - accuracy: 0.8513 - val_loss: 0.6423 - val_accuracy: 0.7960\n",
      "Epoch 30/50\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.4293 - accuracy: 0.8501WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.4293 - accuracy: 0.8501 - val_loss: 0.6517 - val_accuracy: 0.7959\n",
      "Epoch 31/50\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.4270 - accuracy: 0.8511WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.4270 - accuracy: 0.8511 - val_loss: 0.6446 - val_accuracy: 0.7935\n",
      "Epoch 32/50\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.4288 - accuracy: 0.8507WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 166us/sample - loss: 0.4286 - accuracy: 0.8508 - val_loss: 0.6593 - val_accuracy: 0.7920\n",
      "Epoch 33/50\n",
      "49664/50000 [============================>.] - ETA: 0s - loss: 0.4277 - accuracy: 0.8516WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.4281 - accuracy: 0.8515 - val_loss: 0.6543 - val_accuracy: 0.7928\n",
      "Epoch 34/50\n",
      "49728/50000 [============================>.] - ETA: 0s - loss: 0.4112 - accuracy: 0.8575WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.4116 - accuracy: 0.8575 - val_loss: 0.6482 - val_accuracy: 0.7974\n",
      "Epoch 35/50\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.4158 - accuracy: 0.8548WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.4157 - accuracy: 0.8548 - val_loss: 0.6495 - val_accuracy: 0.7957\n",
      "Epoch 36/50\n",
      "49760/50000 [============================>.] - ETA: 0s - loss: 0.4158 - accuracy: 0.8550WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.4165 - accuracy: 0.8548 - val_loss: 0.6441 - val_accuracy: 0.7899\n",
      "Epoch 37/50\n",
      "49728/50000 [============================>.] - ETA: 0s - loss: 0.4161 - accuracy: 0.8556WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.4161 - accuracy: 0.8557 - val_loss: 0.6365 - val_accuracy: 0.8017\n",
      "Epoch 38/50\n",
      "49888/50000 [============================>.] - ETA: 0s - loss: 0.4104 - accuracy: 0.8561WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.4102 - accuracy: 0.8562 - val_loss: 0.6566 - val_accuracy: 0.7952\n",
      "Epoch 39/50\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.4081 - accuracy: 0.8587WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.4077 - accuracy: 0.8588 - val_loss: 0.6593 - val_accuracy: 0.7982\n",
      "Epoch 40/50\n",
      "49632/50000 [============================>.] - ETA: 0s - loss: 0.4038 - accuracy: 0.8615WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.4041 - accuracy: 0.8613 - val_loss: 0.6683 - val_accuracy: 0.7966\n",
      "Epoch 41/50\n",
      "49664/50000 [============================>.] - ETA: 0s - loss: 0.3981 - accuracy: 0.8623WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.3981 - accuracy: 0.8624 - val_loss: 0.6588 - val_accuracy: 0.7955\n",
      "Epoch 42/50\n",
      "49728/50000 [============================>.] - ETA: 0s - loss: 0.3964 - accuracy: 0.8621WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 166us/sample - loss: 0.3967 - accuracy: 0.8620 - val_loss: 0.7106 - val_accuracy: 0.7928\n",
      "Epoch 43/50\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.4026 - accuracy: 0.8606WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.4022 - accuracy: 0.8607 - val_loss: 0.6797 - val_accuracy: 0.7868\n",
      "Epoch 44/50\n",
      "49728/50000 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8656WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.3903 - accuracy: 0.8652 - val_loss: 0.7029 - val_accuracy: 0.7886\n",
      "Epoch 45/50\n",
      "49696/50000 [============================>.] - ETA: 0s - loss: 0.3934 - accuracy: 0.8646WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.3940 - accuracy: 0.8644 - val_loss: 0.6996 - val_accuracy: 0.7905\n",
      "Epoch 46/50\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8663WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.3872 - accuracy: 0.8662 - val_loss: 0.6632 - val_accuracy: 0.7971\n",
      "Epoch 47/50\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.3980 - accuracy: 0.8640WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.3979 - accuracy: 0.8641 - val_loss: 0.6517 - val_accuracy: 0.7982\n",
      "Epoch 48/50\n",
      "49952/50000 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8651WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.3890 - accuracy: 0.8651 - val_loss: 0.6549 - val_accuracy: 0.8009\n",
      "Epoch 49/50\n",
      "49760/50000 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8662WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.3827 - accuracy: 0.8663 - val_loss: 0.6723 - val_accuracy: 0.7991\n",
      "Epoch 50/50\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8683WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.3848 - accuracy: 0.8682 - val_loss: 0.6897 - val_accuracy: 0.7951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f65340577f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again training for 50 more epochs \n",
    "model.fit(x_train,y_train,          \n",
    "          validation_data=(x_test,y_test),\n",
    "          epochs=50,\n",
    "          batch_size=32, callbacks=[mckpt],workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7V6PFjP56HB-"
   },
   "outputs": [],
   "source": [
    "# Predicting on test data \n",
    "y_pred_class = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3Rk1xR6k4syw",
    "outputId": "427175db-bfcb-48ff-901d-82a7967d7fb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7951"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "# Score CNN model\n",
    "metrics.accuracy_score(test_y, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "f3x_Lkdm8DsV",
    "outputId": "5cee1f2c-98c8-4c98-e876-eb87987fb80c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82      1000\n",
      "           1       0.94      0.86      0.90      1000\n",
      "           2       0.75      0.69      0.72      1000\n",
      "           3       0.62      0.63      0.62      1000\n",
      "           4       0.80      0.73      0.76      1000\n",
      "           5       0.68      0.75      0.71      1000\n",
      "           6       0.75      0.90      0.82      1000\n",
      "           7       0.90      0.81      0.85      1000\n",
      "           8       0.82      0.92      0.87      1000\n",
      "           9       0.85      0.90      0.88      1000\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report  CNN model\n",
    "print(metrics.classification_report(test_y, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vu_Gno-z11dP"
   },
   "source": [
    "Q7. Import packages required for VGG16\n",
    "\n",
    "*   `tf.keras.application`\n",
    "> VGG16, preprocess_input, decode_predictions\n",
    "*   `tf.keras.preprocessing`\n",
    "> load_img, img_to_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDcWn4jQRW2v"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import array_to_img,load_img,img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zlfH3ImV2C6i"
   },
   "source": [
    "Q8. Load image\n",
    "\n",
    "\n",
    "*   Mount Google Drive\n",
    "*   Navigate to image location (use `os`)\n",
    "*   Load image and assign a variable (use `load_img`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m8060Dfn2Al6",
    "outputId": "982e272c-4fc1-4f89-e751-afc28b46d459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlHKuc83Uv6Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive/ANN DL/Image')\n",
    "\n",
    "# load an image from file\n",
    "image = load_img('/content/drive/My Drive/ANN DL/Image/49436743043_2441587ab9_c.jpg', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "6A3BZlSHasvu",
    "outputId": "c69b957d-8c2c-43b3-c971-e3c46131b779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49436743043_2441587ab9_c.jpg\n",
      "49438170746_8378201627_c.jpg\n",
      "4994221690_d070e8a355_c.jpg\n",
      "49441887332_107afa786d_c.jpg\n"
     ]
    }
   ],
   "source": [
    "# using loop opreation for fectching 4 images and applying pre-processing \n",
    "images = []\n",
    "for img in os.listdir(r'/content/drive/My Drive/ANN DL/Image/'):\n",
    "    print(img)\n",
    "    img = load_img(r'/content/drive/My Drive/ANN DL/Image' +'/'+ img, target_size=(224, 224))\n",
    "    #print(plt.imshow(img))\n",
    "    img = img_to_array(img)\n",
    "    img = img2.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "    img = preprocess_input(img)\n",
    "    images.append(img)\n",
    "images = np.vstack(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0rK0I_E3-tLi"
   },
   "source": [
    "Q9. Preprocess the image\n",
    "\n",
    "\n",
    "*   Convert image into array (use `img_to_array`)\n",
    "*   Check shape of image\n",
    "*   Reshape image into 4 dimensional format (use `reshape`)\n",
    "*   Prepare the image for VGG16 (Use `preprocess_input()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-YJ-kw0IBx3k",
    "outputId": "d56145cb-d626-4aa4-80c4-38d598b542cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image_array (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert the image pixels to a numpy array\n",
    "image_array = img_to_array(image)\n",
    "\n",
    "# Check shape of image\n",
    "print ('shape of image_array',image_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vGDlRhDGWJwC",
    "outputId": "bac5cbac-d863-4b97-9231-3d97c3065aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image_array (1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# reshape data for the model\n",
    "image_array = image_array.reshape((1, image_array.shape[0], image_array.shape[1], image_array.shape[2]))\n",
    "print ('shape of image_array',image_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-HBUpxpIWygs"
   },
   "outputs": [],
   "source": [
    "# prepare the image for the VGG model\n",
    "image_vgg16 = preprocess_input(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S7HvBkNHX3b3"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "id": "fSiW-NngfyZQ",
    "outputId": "398a7719-e487-45ca-e11b-4144bbb8aea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L8GCuI6b3VWA"
   },
   "source": [
    "Q10. Predict the Class of image\n",
    "\n",
    "\n",
    "*   Use `predict()` to calculate probabilities (Assign a variable)\n",
    "*   Convert the probabilities to class labels (Use `decode_predictions`)(Assign a variable)\n",
    "*   Print the classification results\n",
    "\n",
    "\n",
    "> Use \n",
    ">*  label = label[0][0]\n",
    ">*   print('%s (%.2f%%)' % (label[1], label[2]*100))\n",
    ">*(where label is variable assigned for `decode_predictions` )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdpZWegdBy6d"
   },
   "outputs": [],
   "source": [
    "y_perd = model.predict(image_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrR54BqJYl5J"
   },
   "outputs": [],
   "source": [
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(y_perd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JZBc768oY9OI",
    "outputId": "b46286de-8f37-48a1-b96d-ff7676acbddb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('n01833805', 'hummingbird', 0.36529168)"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KtTaFXdhLeRa"
   },
   "source": [
    "#NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BdGoZI6GPiMa"
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxuOeh7gLjsg"
   },
   "source": [
    "Read file 'tweets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrBDwzPLOz5M"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ia5dKPjfozhB"
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tweets.csv',encoding = 'mac_roman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NdOrtYQIphtO",
    "outputId": "ee5af3c7-69fe-48c0-90da-b2ec98d3ed45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tweets (9093, 3)\n"
     ]
    }
   ],
   "source": [
    "print ('shape of tweets',tweets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FGKTjeY0Owyc"
   },
   "source": [
    "**Drop null values**\n",
    "\n",
    "*   Drop all the rows with null values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCEMFY5BPFWa"
   },
   "outputs": [],
   "source": [
    "df = tweets.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bHT9dSYiO7zo",
    "outputId": "b275e046-6d43-462f-abbb-0dc97c08c2c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of df (3291, 3)\n"
     ]
    }
   ],
   "source": [
    "print ('shape of df',df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JILOg2-0O8t6"
   },
   "source": [
    "**Print the dataframe**\n",
    "*   print initial 5 rows of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "b6VLTLbtPQKj",
    "outputId": "673b9620-01d0-4ae2-d13b-7132b0a41974"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPJR8H6SPQqi"
   },
   "source": [
    "##Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HUX0tTpDQZLo"
   },
   "source": [
    "**Preprocess data**\n",
    "\n",
    "\n",
    "*   convert all text to lowercase - use .lower()\n",
    "*   select only numbers, alphabets, and #+_ from text - use re.sub()\n",
    "*   strip all the text - use .strip() [To remove extra spaces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nnEdxmsqG9M"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "YMOoHrcuQzBK",
    "outputId": "ab99e159-a448-4149-d26a-8b3c032cb530"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raj_lodha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\raj_lodha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df['tweet_text'] = df['tweet_text'].apply(lambda s: re.sub('[^0-9a-z #+_]','',s))\n",
    "df['tweet_text'] = df['tweet_text'].apply(lambda s: s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "eJfVM54OrUWp",
    "outputId": "59d5d26a-4189-445d-831e-4759be5708e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raj_lodha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['tweet_text'] = df['tweet_text'].apply(lambda s: s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "PxVUtl5Ori5h",
    "outputId": "9495a0bd-9dbe-40b5-de85-ca4087e94c64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wesley83  have a 3 ihone fter 3 hrs tweeting a...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jessedee now about fludapp  wesome iadihone ap...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>swonderlin an not wait for #iad 2 also hey sho...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sxsw  hope this years festival isnt as crashy ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sxtxstate great stuff on ri # arissa ayer oogl...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  wesley83  have a 3 ihone fter 3 hrs tweeting a...   \n",
       "1  jessedee now about fludapp  wesome iadihone ap...   \n",
       "2  swonderlin an not wait for #iad 2 also hey sho...   \n",
       "3  sxsw  hope this years festival isnt as crashy ...   \n",
       "4  sxtxstate great stuff on ri # arissa ayer oogl...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "os_is_IoQzbH"
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "WkCmfmPPQ7R6",
    "outputId": "a2bc7517-b1ff-4fe9-ba16-96441c861fae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'Positive emotion',\n",
       "       'No emotion toward brand or product', \"I can't tell\"], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "YGxBdvbBs2ju",
    "outputId": "b988b3b6-fdd8-4f62-a997-db966f5d831b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive emotion                      2672\n",
       "Negative emotion                       519\n",
       "No emotion toward brand or product      91\n",
       "I can't tell                             9\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRI31RfMRG40"
   },
   "source": [
    "**Preprocess data**\n",
    "\n",
    "\n",
    "*   in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
    "select only those rows where value equal to \"positive emotion\" or \"negative emotion\"\n",
    "*   find the value counts of \"positive emotion\" and \"negative emotion\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JknlN8cBs9XZ"
   },
   "outputs": [],
   "source": [
    "df = df[(df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Negative emotion') | (df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Positive emotion')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "7DcubmuDtihk",
    "outputId": "93772779-562b-4503-cd74-e757d39dd9ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wesley83  have a 3 ihone fter 3 hrs tweeting a...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jessedee now about fludapp  wesome iadihone ap...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>swonderlin an not wait for #iad 2 also hey sho...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sxsw  hope this years festival isnt as crashy ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sxtxstate great stuff on ri # arissa ayer oogl...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  wesley83  have a 3 ihone fter 3 hrs tweeting a...   \n",
       "1  jessedee now about fludapp  wesome iadihone ap...   \n",
       "2  swonderlin an not wait for #iad 2 also hey sho...   \n",
       "3  sxsw  hope this years festival isnt as crashy ...   \n",
       "4  sxtxstate great stuff on ri # arissa ayer oogl...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_L3AabRRZvq"
   },
   "source": [
    "##Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQMO-RQURdUI"
   },
   "source": [
    "### Encode labels\n",
    "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
    "    - change \"positive emotion\" to 1\n",
    "    - change \"negative emotion\" to 0\n",
    "- use map function to replace values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ec7kw9n1Rjdc"
   },
   "outputs": [],
   "source": [
    "df['label']= df.is_there_an_emotion_directed_at_a_brand_or_product.map({'Negative emotion': 0, 'Positive emotion':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "l6v-eaGJvFNp",
    "outputId": "de9bd354-e920-43e5-a426-65ed209e36d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wesley83  have a 3 ihone fter 3 hrs tweeting a...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jessedee now about fludapp  wesome iadihone ap...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>swonderlin an not wait for #iad 2 also hey sho...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sxsw  hope this years festival isnt as crashy ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sxtxstate great stuff on ri # arissa ayer oogl...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  wesley83  have a 3 ihone fter 3 hrs tweeting a...   \n",
       "1  jessedee now about fludapp  wesome iadihone ap...   \n",
       "2  swonderlin an not wait for #iad 2 also hey sho...   \n",
       "3  sxsw  hope this years festival isnt as crashy ...   \n",
       "4  sxtxstate great stuff on ri # arissa ayer oogl...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  label  \n",
       "0                                   Negative emotion      0  \n",
       "1                                   Positive emotion      1  \n",
       "2                                   Positive emotion      1  \n",
       "3                                   Negative emotion      0  \n",
       "4                                   Positive emotion      1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UIy_xlRbRj_H"
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKuiAcwhRmhz"
   },
   "source": [
    "### Get feature and label\n",
    "- get column \"tweet_text\" as feature\n",
    "- get column \"is_there_an_emotion_directed_at_a_brand_or_product\" as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NV3WlXurRokY"
   },
   "outputs": [],
   "source": [
    "x = df.tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g5urKp3CvowQ"
   },
   "outputs": [],
   "source": [
    "y=df.is_there_an_emotion_directed_at_a_brand_or_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "xYOvdeCjvs87",
    "outputId": "e0e2e46f-1c0b-46e4-a622-1fa0f0183e92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x (3191,)\n",
      "shape of y (3191,)\n"
     ]
    }
   ],
   "source": [
    "print('shape of x',x.shape)\n",
    "print('shape of y',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1F4UCW9IRpWL"
   },
   "source": [
    "### Create train and test data\n",
    "- use train_test_split to get train and test set\n",
    "- set a random_state\n",
    "- test_size: 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BWF9LBDGRsKy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfmPJW0FwTeF"
   },
   "outputs": [],
   "source": [
    "# split the new DataFrame into training and testing sets [Default test size = 25%]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=1,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FVdPlJSfxFsK",
    "outputId": "76d9fd48-c311-4369-c128-fa0897f97611"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2393,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oFPxcFWvxN4t",
    "outputId": "69fae316-a118-4bd5-e24e-9a3ba135a1cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(798,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kM4xxNXYRsq-"
   },
   "source": [
    "## Question 6\n",
    "\n",
    "### Vectorize data\n",
    "- create document-term matrix\n",
    "- use CountVectorizer()\n",
    "    - ngram_range: (1, 2)\n",
    "    - stop_words: 'english'\n",
    "    - min_df: 2   \n",
    "- do fit_transform on X_train\n",
    "- do transform on X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v1l9btlNRwfR"
   },
   "outputs": [],
   "source": [
    "# use CountVectorizer to create document-term matrices from X_train and X_test\n",
    "vect = CountVectorizer(ngram_range=(1,2),stop_words='english',min_df=2)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6AzeV5ZRxZD"
   },
   "source": [
    "## Question 7\n",
    "\n",
    "### Select classifier logistic regression\n",
    "- use logistic regression for predicting sentiment of the given tweet\n",
    "- initialize classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rb4NWC5R0lV"
   },
   "outputs": [],
   "source": [
    "# use logistic regression with text column only\n",
    "logreg = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnIVaronR1MS"
   },
   "source": [
    "### Fit the classifer\n",
    "- fit logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "-fwF08J2R4Og",
    "outputId": "232eb3ae-2e81-44df-e978-daba815d0c72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raj_lodha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_dtm, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7k4abGDR4oR"
   },
   "source": [
    "## Question 8\n",
    "\n",
    "### Select classifier naive bayes\n",
    "- use naive bayes for predicting sentiment of the given tweet\n",
    "- initialize classifier\n",
    "- use MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hiWWDTj8R8b9"
   },
   "outputs": [],
   "source": [
    " nb = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yONFSFc_R9FF"
   },
   "source": [
    "### Fit the classifer\n",
    "- fit naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HPFTYhNBSA1N",
    "outputId": "c34ce39f-20e7-48f5-82fe-74124d3b4365"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_dtm, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fSTMQEVhSJ04"
   },
   "source": [
    "## Question 9\n",
    "\n",
    "### Make predictions on logistic regression\n",
    "- use your trained logistic regression model to make predictions on X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tb4xte6vSVas"
   },
   "outputs": [],
   "source": [
    "y_pred_class_l = logreg.predict(X_test_dtm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WZqjZJiXR_6x"
   },
   "source": [
    "### Make predictions on naive bayes\n",
    "- use your trained naive bayes model to make predictions on X_test\n",
    "- use a different variable name to store predictions so that they are kept separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FoClZXgTSVAq"
   },
   "outputs": [],
   "source": [
    "y_pred_class_nb = nb.predict(X_test_dtm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHZ_D-zsSXR7"
   },
   "source": [
    "## Question 10\n",
    "\n",
    "### Calculate accuracy of logistic regression\n",
    "- check accuracy of logistic regression classifer\n",
    "- use sklearn.metrics.accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J1luBwomSZ7w",
    "outputId": "33c0b130-70c0-44b4-d50a-a5fae84352c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8609022556390977\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, y_pred_class_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mc9l9vNbSas-"
   },
   "source": [
    "### Calculate accuracy of naive bayes\n",
    "- check accuracy of naive bayes classifer\n",
    "- use sklearn.metrics.accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xvfXGyPNSdC5",
    "outputId": "10a2027d-4bfa-4cf4-ef9e-77d3c6be6fba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8583959899749374\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R8_Internal_Lab_ACV_NLP_Question_solved.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
