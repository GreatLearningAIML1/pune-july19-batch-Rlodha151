{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R6_ExternalLab_TEST.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YYk8NG3yOIT9"},"source":["### A MNIST-like fashion product database\n","\n","In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tFO6PuxzOIT_"},"source":["### Load tensorflow"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"efNjNImfOIUC","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"c16d0874-b50c-4d45-9001-e01c8890dd81","executionInfo":{"status":"ok","timestamp":1584192293794,"user_tz":-330,"elapsed":3117,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf \n","print (tf.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n","2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"l9C4aAIGOIUH","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HcoZBStrOIUQ"},"source":["### Collect Data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XA1WsFSeOIUS","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"42ae40c0-32f0-442b-de1e-08ea29c6efeb","executionInfo":{"status":"ok","timestamp":1584192298435,"user_tz":-330,"elapsed":1236,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["import keras"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qnbx7TyQOIUY","colab":{}},"source":["(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cS98BSrlGOrb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"0be83f09-88a6-412d-fe37-56f36fe554d4","executionInfo":{"status":"ok","timestamp":1584192307070,"user_tz":-330,"elapsed":1336,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["import numpy as np\n","print ('shape of trainX',trainX.shape)\n","print ('shape of testX',testX.shape)\n","print ('shape of trainY',trainY.shape)\n","print ('shape of testY',testY.shape)\n","print ('number of unique entries in lable column ',np.unique(testY, axis=0))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["shape of trainX (60000, 28, 28)\n","shape of testX (10000, 28, 28)\n","shape of trainY (60000,)\n","shape of testY (10000,)\n","number of unique entries in lable column  [0 1 2 3 4 5 6 7 8 9]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UbiHj5YPOIUc","outputId":"f0f03b65-5161-4446-8db1-2e3c11e5de79","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1584192311877,"user_tz":-330,"elapsed":1248,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["# checking few lables \n","print(testY[0:5])\n","lables = trainY"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[9 2 1 1 6]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hxPCV5zvGOrk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"c304a47b-f4fe-4d59-c0ea-4ea46ba7dcdb","executionInfo":{"status":"ok","timestamp":1584192316573,"user_tz":-330,"elapsed":1282,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["print ('data type of trainX is ',trainX.dtype)\n","print ('data type of testX is ',testX.dtype)\n","print ('data type of trainY is ',trainY.dtype)\n","print ('data type of testY is ',testY.dtype)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["data type of trainX is  uint8\n","data type of testX is  uint8\n","data type of trainY is  uint8\n","data type of testY is  uint8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OKCeNHBiGOro","colab_type":"code","colab":{}},"source":["# we need our data to present in as float32\n","# converting uint8 to float32\n","trainX =np.array(trainX).astype('float32')\n","testX = np.array(testX).astype('float32')\n","trainY =np.array(trainY).astype('float32')\n","testY = np.array(testY).astype('float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NvEyWpWnGOrs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"cee54308-74e9-4608-c0df-1b06f0df5b29","executionInfo":{"status":"ok","timestamp":1584192325759,"user_tz":-330,"elapsed":1499,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["print ('data type of trainX is ',trainX.dtype)\n","print ('data type of testX is ',testX.dtype)\n","print ('data type of trainY is',trainY.dtype)\n","print ('data type of testY is ',testY.dtype)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["data type of trainX is  float32\n","data type of testX is  float32\n","data type of trainY is float32\n","data type of testY is  float32\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lDAYzkwyOIUj"},"source":["### Convert both training and testing labels into one-hot vectors.\n","\n","**Hint:** check **tf.keras.utils.to_categorical()**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vBlfYlANOIUk","colab":{}},"source":["# converterting catagorical variable of test set into one hot encoding to make use of softmax \n","testY = tf.keras.utils.to_categorical(testY, num_classes=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9MZSGxfGOr1","colab_type":"code","colab":{}},"source":["# converterting catagorical variable of train set into one hot encoding\n","trainY = tf.keras.utils.to_categorical(trainY,num_classes=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RHV3b9mzOIUq","outputId":"93726237-ce5a-46b6-b3d1-5ba21fcd4d04","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1584192338874,"user_tz":-330,"elapsed":1264,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["# Checking shape and first 5 example of train set\n","print(trainY.shape)\n","print('First 5 examples now are: ', trainY[0:5])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(60000, 10)\n","First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FwhQ8e7VOIUw"},"source":["### Visualize the data\n","\n","Plot first 10 images in the triaining set and their labels."]},{"cell_type":"code","metadata":{"id":"DorqrUYVGOr-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":251},"outputId":"0e6a8496-cb15-4893-c233-ba813c9e0cb5","executionInfo":{"status":"ok","timestamp":1584192357960,"user_tz":-330,"elapsed":1465,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["#Plot first 10 images in the triaining set and their labels\n","import matplotlib.pyplot as plt\n","# to Print plots in jupyter notebook \n","%matplotlib inline \n","plt.figure(figsize=(10,10)) # figure size \n","for i in range(10): # looping for first 10 element of training set\n","    plt.subplot(5,5,i+1) # creating sub plot for  ploting figure \n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(trainX[i], cmap=plt.cm.binary) # Ploting binry figures \n","    plt.xlabel(lables[i]) # giving Lables to plot images \n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAj0AAADqCAYAAABJNfS/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCEkCv4f+mkpusOvBgAAAAAASUVORK5CYII=\n","text/plain":["<Figure size 720x720 with 10 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"l4TbJGeSOIU4"},"source":["### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ac06XZZTOIU6","colab":{}},"source":["# Initialize Sequential model\n","model = tf.keras.models.Sequential() # Instantiating keras sequential models from keras \n","\n","# First layer (input layer) of  28*28 = 784 after flattening the image of 28 * 28 picxels\n","model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n","# Final layer with activation function as softmax and 10 neurons \n","model.add(tf.keras.layers.Dense(10, activation='softmax'))\n","\n","# Create optimizer with non-default learning rate\n","sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n","\n","# Compile the model\n","model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PVZc7wxwGOsI","colab_type":"code","colab":{}},"source":["# To visualize performance of traing and testing via server by using tensorboard\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='log_dir_1')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3hQpLv3aOIU_"},"source":["### Execute the model using model.fit()"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O59C_-IgOIVB","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"31bda681-4b3c-424c-f37a-4f36fa6bb453","executionInfo":{"status":"ok","timestamp":1584192506413,"user_tz":-330,"elapsed":34169,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["# fiting our model with 10 epochs \n","model.fit(trainX, trainY, validation_data=(testX, testY), epochs=10,callbacks=[tensorboard_callback])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/10\n","60000/60000 [==============================] - 3s 57us/sample - loss: 6101.4648 - accuracy: 0.7396 - val_loss: 11314.8742 - val_accuracy: 0.7096\n","Epoch 2/10\n","60000/60000 [==============================] - 3s 55us/sample - loss: 4877.0309 - accuracy: 0.7774 - val_loss: 4737.6207 - val_accuracy: 0.7976\n","Epoch 3/10\n","60000/60000 [==============================] - 3s 55us/sample - loss: 4700.8658 - accuracy: 0.7859 - val_loss: 3470.2084 - val_accuracy: 0.8066\n","Epoch 4/10\n","60000/60000 [==============================] - 3s 55us/sample - loss: 4615.8329 - accuracy: 0.7906 - val_loss: 5868.0137 - val_accuracy: 0.7542\n","Epoch 5/10\n","60000/60000 [==============================] - 3s 56us/sample - loss: 4400.2570 - accuracy: 0.7945 - val_loss: 3776.7541 - val_accuracy: 0.7917\n","Epoch 6/10\n","60000/60000 [==============================] - 3s 58us/sample - loss: 4419.0987 - accuracy: 0.7944 - val_loss: 3626.0978 - val_accuracy: 0.8081\n","Epoch 7/10\n","60000/60000 [==============================] - 3s 55us/sample - loss: 4452.5639 - accuracy: 0.7945 - val_loss: 10785.6548 - val_accuracy: 0.7190\n","Epoch 8/10\n","60000/60000 [==============================] - 3s 55us/sample - loss: 4441.5717 - accuracy: 0.7979 - val_loss: 2970.1427 - val_accuracy: 0.8268\n","Epoch 9/10\n","60000/60000 [==============================] - 3s 55us/sample - loss: 4310.1416 - accuracy: 0.7996 - val_loss: 16301.4424 - val_accuracy: 0.5945\n","Epoch 10/10\n","60000/60000 [==============================] - 3s 55us/sample - loss: 4338.7667 - accuracy: 0.7998 - val_loss: 8023.5748 - val_accuracy: 0.7388\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7efd01b77710>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"QMS6HAPkGOsQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"13a31387-ab16-4528-dfd4-8d85c6b8e6ce","executionInfo":{"status":"ok","timestamp":1584193586120,"user_tz":-330,"elapsed":2409,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["# serialize model to JSON\n","model_json = model.to_json() \n","with open(\"model.json\", \"w\") as json_file: # \n","    json_file.write(model_json) # saving our model into to json file format \n","# Json file formate can be used to again load our model file to test our model across server \n","# serialize weights to HDF5\n","model.save_weights(\"model.h5\") # saving our model into to HdF.5 file format\n","# HDF.5 file formate can be used to again load our model file to test our model\n","print(\"Saved model to disk\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Saved model to disk\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JdzDtGwDOIVF"},"source":["### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kndfpdidOIVI","colab":{}},"source":["# Initialize Sequential model\n","model_batch_norm = tf.keras.models.Sequential()\n","\n","# Reshape data from 2D to 1D -> 28x28 to 784\n","model_batch_norm.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n","\n","# Normalize the data\n","model_batch_norm.add(tf.keras.layers.BatchNormalization())\n","\n","# Add Dense Layer which provides 10 Outputs after applying softmax\n","model_batch_norm.add(tf.keras.layers.Dense(10, activation='softmax'))\n","\n","\n","\n","# Create optimizer with non-default learning rate\n","sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n","\n","# Compile the model\n","model_batch_norm.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDFhIqh8GOsZ","colab_type":"code","colab":{}},"source":["# To visualize performance of traing and testing via server by using tensorboard\n","tensorboard = tf.keras.callbacks.TensorBoard(log_dir='log_dir_2')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mwk3T5LJOIVN"},"source":["### Execute the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JNLR8tcBOIVP","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e8750fde-9e94-4a4e-c006-39623fe2a19a","executionInfo":{"status":"ok","timestamp":1584197905136,"user_tz":-330,"elapsed":131138,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["# fiting our model with 30 epochs along with batch normalization \n","model_batch_norm.fit(trainX, trainY, validation_data=(testX, testY), epochs=30,batch_size = 32 ,callbacks=[tensorboard])"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/30\n","60000/60000 [==============================] - 4s 74us/sample - loss: 0.5470 - accuracy: 0.8134 - val_loss: 0.5031 - val_accuracy: 0.8290\n","Epoch 2/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4866 - accuracy: 0.8321 - val_loss: 0.4984 - val_accuracy: 0.8340\n","Epoch 3/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4691 - accuracy: 0.8373 - val_loss: 0.4967 - val_accuracy: 0.8349\n","Epoch 4/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4631 - accuracy: 0.8404 - val_loss: 0.4854 - val_accuracy: 0.8352\n","Epoch 5/30\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.4564 - accuracy: 0.8428 - val_loss: 0.4854 - val_accuracy: 0.8380\n","Epoch 6/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4523 - accuracy: 0.8432 - val_loss: 0.5206 - val_accuracy: 0.8328\n","Epoch 7/30\n","60000/60000 [==============================] - 4s 74us/sample - loss: 0.4460 - accuracy: 0.8451 - val_loss: 0.4966 - val_accuracy: 0.8322\n","Epoch 8/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4463 - accuracy: 0.8446 - val_loss: 0.4978 - val_accuracy: 0.8304\n","Epoch 9/30\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.4419 - accuracy: 0.8466 - val_loss: 0.4941 - val_accuracy: 0.8366\n","Epoch 10/30\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.4428 - accuracy: 0.8454 - val_loss: 0.4790 - val_accuracy: 0.8386\n","Epoch 11/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4394 - accuracy: 0.8459 - val_loss: 0.4989 - val_accuracy: 0.8343\n","Epoch 12/30\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.4387 - accuracy: 0.8467 - val_loss: 0.5132 - val_accuracy: 0.8253\n","Epoch 13/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4375 - accuracy: 0.8472 - val_loss: 0.4879 - val_accuracy: 0.8389\n","Epoch 14/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4367 - accuracy: 0.8474 - val_loss: 0.5038 - val_accuracy: 0.8337\n","Epoch 15/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4336 - accuracy: 0.8485 - val_loss: 0.4845 - val_accuracy: 0.8343\n","Epoch 16/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4320 - accuracy: 0.8471 - val_loss: 0.4954 - val_accuracy: 0.8378\n","Epoch 17/30\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.4293 - accuracy: 0.8502 - val_loss: 0.4948 - val_accuracy: 0.8380\n","Epoch 18/30\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.4297 - accuracy: 0.8506 - val_loss: 0.5064 - val_accuracy: 0.8324\n","Epoch 19/30\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.4280 - accuracy: 0.8489 - val_loss: 0.4997 - val_accuracy: 0.8363\n","Epoch 20/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4292 - accuracy: 0.8488 - val_loss: 0.4995 - val_accuracy: 0.8353\n","Epoch 21/30\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.4301 - accuracy: 0.8491 - val_loss: 0.5195 - val_accuracy: 0.8375\n","Epoch 22/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4283 - accuracy: 0.8505 - val_loss: 0.5033 - val_accuracy: 0.8325\n","Epoch 23/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4242 - accuracy: 0.8519 - val_loss: 0.5252 - val_accuracy: 0.8374\n","Epoch 24/30\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.4260 - accuracy: 0.8497 - val_loss: 0.4894 - val_accuracy: 0.8392\n","Epoch 25/30\n","60000/60000 [==============================] - 4s 71us/sample - loss: 0.4265 - accuracy: 0.8505 - val_loss: 0.4816 - val_accuracy: 0.8331\n","Epoch 26/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4266 - accuracy: 0.8498 - val_loss: 0.4817 - val_accuracy: 0.8376\n","Epoch 27/30\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.4238 - accuracy: 0.8506 - val_loss: 0.4912 - val_accuracy: 0.8375\n","Epoch 28/30\n","60000/60000 [==============================] - 4s 71us/sample - loss: 0.4230 - accuracy: 0.8506 - val_loss: 0.5098 - val_accuracy: 0.8351\n","Epoch 29/30\n","60000/60000 [==============================] - 4s 71us/sample - loss: 0.4231 - accuracy: 0.8502 - val_loss: 0.4992 - val_accuracy: 0.8371\n","Epoch 30/30\n","60000/60000 [==============================] - 4s 71us/sample - loss: 0.4228 - accuracy: 0.8511 - val_loss: 0.5084 - val_accuracy: 0.8392\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7efd010899e8>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"JrBi2LBKGOsh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e4f759a3-5da1-428c-d23e-11395cc1dffd","executionInfo":{"status":"ok","timestamp":1584197925898,"user_tz":-330,"elapsed":1360,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["# serialize model to JSON\n","model_json = model_batch_norm.to_json()\n","with open(\"model_batch_norm.json\", \"w\") as json_file:# saving our model into to json file format \n","# Json file formate can be used to again load our model file to test our model across server\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(\"model_batch_norm.h5\") # saving our model into to HdF.5 file format\n","# HDF.5 file formate can be used to again load our model file to test our mode\n","print(\"Saved model to disk\")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Saved model to disk\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Py-KwkmjOIVU"},"source":["### Customize the learning rate to 0.001 in sgd optimizer and run the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yLXUE9jWOIVV","colab":{}},"source":["# Initialize Sequential model\n","model_batch_norm_coustom_learning  = tf.keras.models.Sequential()\n","\n","# Reshape data from 2D to 1D -> 28x28 to 784\n","model_batch_norm_coustom_learning.add(tf.keras.layers.Reshape((784,),input_shape=(28,28)))\n","\n","# Normalize the data\n","model_batch_norm_coustom_learning.add(tf.keras.layers.BatchNormalization())\n","\n","# Add Dense Layer which provides 10 Outputs after applying softmax\n","model_batch_norm_coustom_learning.add(tf.keras.layers.Dense(10, activation='softmax'))\n","\n","\n","# Create optimizer with non-default learning rate \n","sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)\n","\n","# Compile the model\n","model_batch_norm_coustom_learning.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9qwPbgK7GOso","colab_type":"code","colab":{}},"source":["# To visualize performance of traing and testing via server by using tensorboard\n","tb = tf.keras.callbacks.TensorBoard(log_dir='log_dir_3')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pJUqA5T4OIVc","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"24f7edc0-ca5b-4675-d327-f4eae772381a","executionInfo":{"status":"ok","timestamp":1584198068535,"user_tz":-330,"elapsed":23037,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["# fiting our model with 5 epochs along with batch normalization and non-default learning rate \n","model_batch_norm_coustom_learning.fit(trainX, trainY, validation_data=(testX, testY), epochs=5,batch_size = 32 ,callbacks=[tb])"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/5\n","60000/60000 [==============================] - 5s 79us/sample - loss: 0.9278 - accuracy: 0.6846 - val_loss: 0.6845 - val_accuracy: 0.7705\n","Epoch 2/5\n","60000/60000 [==============================] - 4s 71us/sample - loss: 0.6367 - accuracy: 0.7815 - val_loss: 0.6016 - val_accuracy: 0.7944\n","Epoch 3/5\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.5828 - accuracy: 0.8001 - val_loss: 0.5701 - val_accuracy: 0.8037\n","Epoch 4/5\n","60000/60000 [==============================] - 4s 71us/sample - loss: 0.5551 - accuracy: 0.8092 - val_loss: 0.5495 - val_accuracy: 0.8096\n","Epoch 5/5\n","60000/60000 [==============================] - 4s 71us/sample - loss: 0.5366 - accuracy: 0.8152 - val_loss: 0.5402 - val_accuracy: 0.8171\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7efd09e452b0>"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"2F5r3YI3GOsz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"25d47af7-89f4-4481-fdd4-1c473f8a160f","executionInfo":{"status":"ok","timestamp":1584198084655,"user_tz":-330,"elapsed":1223,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["# serialize model to JSON\n","model_json = model_batch_norm_coustom_learning.to_json()\n","with open(\"model_batch_norm_coustom_learning.json\", \"w\") as json_file:\n","    json_file.write(model_json) # saving our model into to json file format \n","# Json file formate can be used to again load our model file to test our model across server\n","# serialize weights to HDF5\n","model.save_weights(\"model_batch_norm_coustom_learning.h5\") # saving our model into to HdF.5 file format\n","# HDF.5 file formate can be used to again load our model file to test our mode\n","print(\"Saved model to disk\")"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Saved model to disk\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"j9CSqKvpOIVk"},"source":["### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GGAad54JOIVm","colab":{}},"source":["# Initialize Sequential model\n","model_batch_norm_layer = tf.keras.models.Sequential()\n","\n","# Reshape data from 2D to 1D -> 28x28 to 784\n","model_batch_norm_layer.add(tf.keras.layers.Reshape((784,),input_shape=(28,28)))\n","\n","# Normalize the data\n","model_batch_norm_layer.add(tf.keras.layers.BatchNormalization())\n","\n","\n","# Add Dense Layer which provides 100 Outputs after applying relu\n","model_batch_norm_layer.add(tf.keras.layers.Dense(100, activation='relu'))\n","\n","# Add Dense Layer which provides 100 Outputs after applying softmax\n","model_batch_norm_layer.add(tf.keras.layers.Dense(100, activation='relu'))\n","\n","\n","# Add Dense Layer which provides 10 Outputs after applying softmax\n","model_batch_norm_layer.add(tf.keras.layers.Dense(10, activation='softmax'))\n","\n","# Create optimizer with non-default learning rate\n","sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n","\n","# Compile the model\n","model_batch_norm_layer.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZJ0mZzaGOs8","colab_type":"text"},"source":["## Review model"]},{"cell_type":"code","metadata":{"id":"0dokmStfGOs9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"e24ba79a-4956-4a4b-a1f1-ec03ed53ced4","executionInfo":{"status":"ok","timestamp":1584198446328,"user_tz":-330,"elapsed":1247,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["# Checking summary, total number of parameters (trainable and non trainable) which are present in our model\n","model_batch_norm_layer.summary()"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","reshape_6 (Reshape)          (None, 784)               0         \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 784)               3136      \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 100)               78500     \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 10)                1010      \n","=================================================================\n","Total params: 92,746\n","Trainable params: 91,178\n","Non-trainable params: 1,568\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gfFGmbZLOIV5"},"source":["### Run the model"]},{"cell_type":"code","metadata":{"id":"ELDM_glVGOtJ","colab_type":"code","colab":{}},"source":["# To visualize performance of traing and testing via server by using tensorboard\n","tb3 = tf.keras.callbacks.TensorBoard(log_dir = 'log_dir_4')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MQ7oIymROIVp","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"12b579f4-07de-401b-d088-c6a3947fb6e5","executionInfo":{"status":"ok","timestamp":1584198707084,"user_tz":-330,"elapsed":63705,"user":{"displayName":"Raj Lodha","photoUrl":"","userId":"08962382632046001537"}}},"source":["# fiting our model with 5 epochs along with batch normalization and non-default learning rate \n","model_batch_norm_layer.fit(trainX, trainY, validation_data=(testX, testY), epochs=10, batch_size = 32 , callbacks=[tb3])"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/10\n","60000/60000 [==============================] - 7s 110us/sample - loss: 0.5015 - accuracy: 0.8214 - val_loss: 0.4073 - val_accuracy: 0.8543\n","Epoch 2/10\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.3802 - accuracy: 0.8619 - val_loss: 0.3924 - val_accuracy: 0.8644\n","Epoch 3/10\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.3411 - accuracy: 0.8749 - val_loss: 0.3611 - val_accuracy: 0.8701\n","Epoch 4/10\n","60000/60000 [==============================] - 6s 104us/sample - loss: 0.3161 - accuracy: 0.8832 - val_loss: 0.3683 - val_accuracy: 0.8699\n","Epoch 5/10\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.2980 - accuracy: 0.8895 - val_loss: 0.3592 - val_accuracy: 0.8745\n","Epoch 6/10\n","60000/60000 [==============================] - 6s 104us/sample - loss: 0.2840 - accuracy: 0.8943 - val_loss: 0.3513 - val_accuracy: 0.8813\n","Epoch 7/10\n","60000/60000 [==============================] - 6s 104us/sample - loss: 0.2722 - accuracy: 0.8984 - val_loss: 0.3505 - val_accuracy: 0.8831\n","Epoch 8/10\n","60000/60000 [==============================] - 6s 104us/sample - loss: 0.2612 - accuracy: 0.9032 - val_loss: 0.3336 - val_accuracy: 0.8825\n","Epoch 9/10\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.2514 - accuracy: 0.9064 - val_loss: 0.3306 - val_accuracy: 0.8852\n","Epoch 10/10\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.2415 - accuracy: 0.9090 - val_loss: 0.3461 - val_accuracy: 0.8824\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7efd09df60f0>"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X-O-fFxnOIVt","colab":{},"outputId":"13801f51-8202-4e2a-f645-07126819d668"},"source":["# serialize model to JSON\n","model_json = model_batch_norm_layer.to_json()\n","with open(\"model_batch_norm_layer.json\", \"w\") as json_file:# saving our model into to json file format \n","# Json file formate can be used to again load our model file to test our model across server\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(\"model_batch_norm_layer.h5\") # saving our model into to HdF.5 file format\n","# HDF.5 file formate can be used to again load our model file to test our mode\n","print(\"Saved model to disk\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Saved model to disk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bIkbMEN5OIV7","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}